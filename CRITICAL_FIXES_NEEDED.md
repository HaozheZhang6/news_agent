# Critical Fixes Needed

## Root Cause of Current Issue

**Problem**: Frontend sends WebSocket messages (audio_chunk, interrupt) BEFORE backend has sent the 'connected' event with the session_id.

**Result**: Backend logs:
```
âš ï¸ WebSocket abc-123... not found, skipping message
Error processing WebSocket message: WebSocket is not connected. Need to call "accept" first.
```

## Fix Required in `frontend/src/components/ContinuousVoiceInterface.tsx`

### Change 1: Import Logger
```typescript
import { logger } from "../utils/logger";
```

### Change 2: Update WebSocket Connection Logic

**CURRENT (BROKEN)**:
```typescript
ws.onopen = () => {
  console.log("âœ… WebSocket connected");
  setIsConnected(true);
  setVoiceState("idle");  // âŒ WRONG: Should NOT go to idle, should stay connecting
};
```

**FIXED**:
```typescript
ws.onopen = () => {
  logger.wsConnect(`ws://localhost:8000/ws/voice?user_id=${userId}`);
  // DON'T set isConnected yet - wait for 'connected' event
  // DON'T change voiceState - stay in 'connecting'
};
```

### Change 3: Handle 'connected' Event Properly

**ADD THIS** in `handleWebSocketMessage`:
```typescript
const handleWebSocketMessage = useCallback((message: any) => {
  logger.wsMessageReceived(message.event, message.data?.session_id);

  switch (message.event) {
    case 'connected':
      // âœ… THIS IS THE CRITICAL FIX
      sessionIdRef.current = message.data.session_id;
      logger.wsConnected(message.data.session_id);
      setIsConnected(true);
      setVoiceState("listening");
      // NOW safe to start recording
      startRecording();
      break;
      
    case 'transcription':
      const transcription = message.data.text;
      setCurrentTranscription(transcription);
      onTranscription?.(transcription);
      logger.transcriptionReceived(transcription);
      break;
      
    // ... rest of cases
  }
}, [onTranscription, onResponse, onError, startRecording]);
```

### Change 4: Gate All WebSocket Sends

**UPDATE sendAudioToBackend**:
```typescript
const sendAudioToBackend = useCallback(async () => {
  // âœ… CRITICAL: Check session_id first
  if (!sessionIdRef.current) {
    logger.warn('audio', 'Cannot send: session not established yet');
    return;
  }

  if (audioChunksRef.current.length === 0) {
    return;
  }

  logger.vadSendTriggered();
  
  const audioBlob = new Blob(audioChunksRef.current, { type: 'audio/webm;codecs=opus' });
  audioChunksRef.current = [];
  
  const reader = new FileReader();
  reader.readAsDataURL(audioBlob);
  reader.onloadend = () => {
    const base64Audio = (reader.result as string).split(',')[1];
    
    if (wsRef.current?.readyState === WebSocket.OPEN && sessionIdRef.current) {
      wsRef.current.send(JSON.stringify({
        event: "audio_chunk",
        data: {
          session_id: sessionIdRef.current,
          audio_chunk: base64Audio,
          format: "webm",
          sample_rate: 48000
        }
      }));
      logger.audioChunkSent(audioBlob.size, sessionIdRef.current);
    }
  };
}, []);
```

**UPDATE sendInterruptSignal**:
```typescript
const sendInterruptSignal = useCallback(() => {
  // âœ… CRITICAL: Check session_id first
  if (!sessionIdRef.current) {
    logger.warn('interrupt', 'Cannot send: session not established yet');
    return;
  }

  if (wsRef.current?.readyState === WebSocket.OPEN) {
    wsRef.current.send(JSON.stringify({
      event: "interrupt",
      data: {
        session_id: sessionIdRef.current,
        reason: "user_started_speaking"
      }
    }));
    logger.interruptSent("user_started_speaking");
  }
}, []);
```

### Change 5: Update startVoiceInteraction

**CURRENT (BROKEN)**:
```typescript
const startVoiceInteraction = useCallback(async () => {
  if (!isConnected) {
    connectWebSocket();
    // âŒ WRONG: This timeout is unreliable
    setTimeout(() => {
      if (wsRef.current?.readyState === WebSocket.OPEN) {
        setVoiceState("listening");
        startRecording();
      }
    }, 1000);
  } else {
    setVoiceState("listening");
    startRecording();
  }
}, [isConnected, connectWebSocket, startRecording]);
```

**FIXED**:
```typescript
const startVoiceInteraction = useCallback(async () => {
  if (!isConnected || !sessionIdRef.current) {
    // Connect and wait for 'connected' event
    // (handleWebSocketMessage will call startRecording when ready)
    connectWebSocket();
  } else {
    // Already connected, just start listening
    setVoiceState("listening");
    startRecording();
  }
}, [isConnected, connectWebSocket, startRecording]);
```

### Change 6: Add Logging Throughout

Add logger calls to:
- `startRecording()` â†’ `logger.audioRecordingStart()`
- `stopRecording()` â†’ `logger.audioRecordingStop()`
- `checkVoiceActivity()` when speech detected â†’ `logger.vadSpeechDetected()`
- `checkVoiceActivity()` when silence detected â†’ `logger.vadSilenceDetected(duration)`
- `stopAudioPlayback()` â†’ `logger.playbackStop()`
- `playNextAudioChunk()` start â†’ `logger.playbackStart()`
- When interrupting â†’ `logger.playbackInterrupted()`

## Fix TTS Chunk Size in Backend

### File: `backend/app/core/streaming_handler.py`

```python
async def stream_tts_audio(
    self,
    text: str,
    voice: str = "en-US-AriaNeural",
    rate: str = "+0%",
    chunk_size: int = 12288  # âœ… CHANGED: 4096 â†’ 12288 for ~3Hz
) -> AsyncGenerator[bytes, None]:
```

**Calculation**:
- Typical TTS bitrate: ~32 kbps (4 KB/s)
- At 4096 bytes: ~1 chunk per second â†’ too slow
- At 8192 bytes: ~2 chunks per second â†’ better
- At 12288 bytes: ~3 chunks per second â†’ target âœ…

## Testing Sequence

1. **Start Backend**:
   ```bash
   make stop-servers
   make run-server
   tail -f logs/detailed/voice_agent_*.log
   ```

2. **Start Frontend**:
   ```bash
   make run-frontend
   ```

3. **Open Browser**:
   - Navigate to `http://localhost:3000`
   - Open DevTools Console
   - Open Network tab â†’ filter "WS"

4. **Click Microphone**:
   - Should see:
     ```
     Frontend Console:
     ğŸ”Œ WS | Connecting to ws://localhost:8000/ws/voice?user_id=...
     ğŸ“¥ WS_RECV | event=connected | session=abc12345...
     ğŸ”Œ WS | Connected | session=abc12345...
     ğŸ¤ AUDIO | Recording started with VAD
     ```
   
   - Backend Log:
     ```
     ğŸ”Œ WS_CONNECT | session=abc12345... | user=def67890...
     ğŸ“¤ WS_SEND | session=abc12345... | event=connected
     ```

5. **Speak a Sentence**:
   - Wait 1 second after stopping
   - Should see:
     ```
     Frontend:
     ğŸ“Š VAD | Speech detected
     ğŸ“Š VAD | Silence detected | duration=1000ms
     â„¹ï¸ VAD | Silence threshold reached â†’ sending audio
     ğŸ“¤ WS_SEND | event=audio_chunk | session=abc12345...
     ğŸ¤ AUDIO | ğŸ“¤ SEND | size=153600 bytes
     
     Backend:
     ğŸ“¥ WS_RECV | session=abc12345... | event=audio_chunk
     ğŸ¤ AUDIO_RECV | session=abc12345... | size=153600 bytes
     ğŸ“ TRANSCRIPTION | session=abc12345... | text='What's the stock price...'
     ğŸ“¤ WS_SEND | session=abc12345... | event=transcription
     ğŸ¤– LLM_RESPONSE | session=abc12345... | text='The current price...'
     ğŸ“¤ WS_SEND | session=abc12345... | event=agent_response
     ğŸ”Š AUDIO_SEND | session=abc12345... | chunk=0
     ğŸ“¤ WS_SEND | session=abc12345... | event=tts_chunk
     (repeat ~3 times per second)
     ```

6. **Interrupt While Speaking**:
   - Start speaking while agent is talking
   - Should see:
     ```
     Frontend:
     ğŸ“Š VAD | Speech detected
     ğŸ›‘ PLAYBACK | ğŸ›‘ Playback interrupted by user speech
     ğŸ“¤ WS_SEND | event=interrupt | session=abc12345...
     
     Backend:
     ğŸ“¥ WS_RECV | session=abc12345... | event=interrupt
     ğŸ›‘ INTERRUPT | session=abc12345... | reason=user_started_speaking
     ğŸ“¤ WS_SEND | session=abc12345... | event=streaming_interrupted
     ```

## Expected Behavior After Fix

1. âœ… **No more "WebSocket not found" errors**
2. âœ… **No more "Need to call accept first" errors**
3. âœ… **Clean connection flow**:
   - Frontend connects
   - Backend sends 'connected'
   - Frontend receives and starts recording
   - User speaks â†’ sends with valid session_id
4. âœ… **Proper logging** in both frontend and backend
5. âœ… **TTS at ~3Hz** (3 chunks per second)
6. âœ… **Error throttling** prevents flooding

## Summary

The key fix is simple but critical:

**âŒ WRONG**: Start recording on `ws.onopen`
**âœ… CORRECT**: Start recording on `message.event === 'connected'`

This ensures `sessionIdRef.current` is set before any messages are sent, preventing all the current errors.

