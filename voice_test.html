<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice News Agent - Live Test</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }
        
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, Oxygen, Ubuntu, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }
        
        .container {
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0,0,0,0.3);
            max-width: 600px;
            width: 100%;
            padding: 40px;
            text-align: center;
        }
        
        h1 {
            color: #333;
            margin-bottom: 10px;
            font-size: 28px;
        }
        
        .subtitle {
            color: #666;
            margin-bottom: 30px;
            font-size: 14px;
        }
        
        .status {
            padding: 12px 20px;
            border-radius: 10px;
            margin-bottom: 30px;
            font-weight: 600;
            font-size: 14px;
        }
        
        .status.disconnected {
            background: #fee;
            color: #c33;
        }
        
        .status.connected {
            background: #efe;
            color: #3a3;
        }
        
        .status.recording {
            background: #ffeaa7;
            color: #d63031;
            animation: pulse 1.5s infinite;
        }
        
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        
        .voice-button {
            width: 200px;
            height: 200px;
            border-radius: 50%;
            border: none;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            font-size: 60px;
            cursor: pointer;
            box-shadow: 0 10px 30px rgba(102, 126, 234, 0.4);
            transition: all 0.3s ease;
            margin: 20px auto;
            display: flex;
            align-items: center;
            justify-content: center;
        }
        
        .voice-button:hover:not(:disabled) {
            transform: scale(1.05);
            box-shadow: 0 15px 40px rgba(102, 126, 234, 0.6);
        }
        
        .voice-button:active:not(:disabled) {
            transform: scale(0.95);
        }
        
        .voice-button.recording {
            background: linear-gradient(135deg, #d63031 0%, #e17055 100%);
            animation: record-pulse 1s infinite;
        }
        
        @keyframes record-pulse {
            0%, 100% { box-shadow: 0 10px 30px rgba(214, 48, 49, 0.4); }
            50% { box-shadow: 0 10px 50px rgba(214, 48, 49, 0.8); }
        }
        
        .voice-button:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        
        .instructions {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            margin-top: 30px;
            text-align: left;
        }
        
        .instructions h3 {
            color: #333;
            margin-bottom: 10px;
            font-size: 16px;
        }
        
        .instructions ul {
            list-style: none;
            color: #666;
            font-size: 14px;
            line-height: 1.8;
        }
        
        .instructions li:before {
            content: "‚úì ";
            color: #667eea;
            font-weight: bold;
            margin-right: 8px;
        }
        
        .transcript-box {
            background: #f8f9fa;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            min-height: 100px;
            text-align: left;
            max-height: 300px;
            overflow-y: auto;
        }
        
        .transcript-item {
            margin: 10px 0;
            padding: 10px;
            border-radius: 8px;
            font-size: 14px;
        }
        
        .transcript-item.user {
            background: #e3f2fd;
            border-left: 3px solid #2196f3;
        }
        
        .transcript-item.agent {
            background: #f1f8e9;
            border-left: 3px solid #8bc34a;
        }
        
        .transcript-item.partial {
            background: #fff3e0;
            border-left: 3px solid #ff9800;
            font-style: italic;
        }
        
        .label {
            font-weight: 600;
            color: #333;
            margin-bottom: 5px;
        }
        
        .text {
            color: #666;
        }
        
        .controls {
            margin-top: 20px;
        }
        
        .control-btn {
            background: #667eea;
            color: white;
            border: none;
            padding: 10px 20px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 14px;
            margin: 5px;
            transition: all 0.2s;
        }
        
        .control-btn:hover {
            background: #5568d3;
        }
        
        .control-btn:disabled {
            background: #ccc;
            cursor: not-allowed;
        }
        
        .audio-visualizer {
            width: 100%;
            height: 60px;
            background: #f8f9fa;
            border-radius: 10px;
            margin: 20px 0;
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 3px;
        }
        
        .audio-bar {
            width: 4px;
            height: 10px;
            background: #667eea;
            border-radius: 2px;
            transition: height 0.1s;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üéôÔ∏è Voice News Agent</h1>
        <p class="subtitle">Click the button and speak naturally</p>
        
        <div id="status" class="status disconnected">
            Connecting...
        </div>
        
        <button id="voiceBtn" class="voice-button" disabled>
            üé§
        </button>
        
        <p id="buttonLabel" style="color: #666; margin-top: 10px;">
            Click to start talking
        </p>
        
        <div class="audio-visualizer" id="visualizer">
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
            <div class="audio-bar"></div>
        </div>
        
        <div class="transcript-box" id="transcript">
            <div style="color: #999; text-align: center;">Conversation will appear here...</div>
        </div>
        
        <div class="controls">
            <button class="control-btn" onclick="clearTranscript()">Clear</button>
            <button class="control-btn" onclick="testConnection()">Test Connection</button>
        </div>
        
        <div class="instructions">
            <h3>How to use:</h3>
            <ul>
                <li>Wait for "Connected" status</li>
                <li>Click the microphone button</li>
                <li>Speak your request (e.g., "Latest tech news")</li>
                <li>Click again to stop and get response</li>
                <li>Listen to the AI voice response</li>
            </ul>
        </div>
    </div>
    
    <audio id="audioPlayer" style="display: none;"></audio>

    <script>
        // Configuration
        const WS_URL = 'ws://localhost:8000/ws/voice';
        const USER_ID = 'test_user_' + Date.now();
        
        // State
        let ws = null;
        let sessionId = null;
        let mediaRecorder = null;
        let audioContext = null;
        let analyser = null;
        let isRecording = false;
        let audioChunks = [];
        let audioQueue = [];
        let isPlaying = false;
        
        // Elements
        const voiceBtn = document.getElementById('voiceBtn');
        const statusDiv = document.getElementById('status');
        const buttonLabel = document.getElementById('buttonLabel');
        const transcriptDiv = document.getElementById('transcript');
        const audioPlayer = document.getElementById('audioPlayer');
        const visualizer = document.getElementById('visualizer');
        
        // Initialize
        window.onload = () => {
            connectWebSocket();
        };
        
        // WebSocket Connection
        function connectWebSocket() {
            const url = `${WS_URL}?user_id=${USER_ID}`;
            console.log('Connecting to:', url);
            
            ws = new WebSocket(url);
            
            ws.onopen = () => {
                console.log('WebSocket connected');
                updateStatus('connected', 'Connected - Ready to talk!');
                voiceBtn.disabled = false;
            };
            
            ws.onmessage = (event) => {
                try {
                    const message = JSON.parse(event.data);
                    handleWebSocketMessage(message);
                } catch (e) {
                    console.error('Failed to parse message:', e);
                }
            };
            
            ws.onerror = (error) => {
                console.error('WebSocket error:', error);
                updateStatus('disconnected', 'Connection error');
            };
            
            ws.onclose = () => {
                console.log('WebSocket closed');
                updateStatus('disconnected', 'Disconnected');
                voiceBtn.disabled = true;
                setTimeout(connectWebSocket, 3000); // Reconnect after 3s
            };
        }
        
        // Handle WebSocket Messages
        function handleWebSocketMessage(message) {
            const { event, data } = message;
            console.log('Received event:', event, data);
            
            switch(event) {
                case 'connected':
                    sessionId = data.session_id;
                    console.log('Session ID:', sessionId);
                    break;
                    
                case 'partial_transcription':
                    updateTranscript('partial', `Hearing: "${data.text}"`);
                    break;
                    
                case 'transcription':
                    updateTranscript('user', data.text);
                    break;
                    
                case 'voice_response':
                    updateTranscript('agent', data.text);
                    if (data.news_items && data.news_items.length > 0) {
                        const newsText = data.news_items.map((item, i) => 
                            `${i+1}. ${item.title}`
                        ).join('\n');
                        updateTranscript('agent', `üì∞ News:\n${newsText}`);
                    }
                    break;
                    
                case 'tts_chunk':
                    playAudioChunk(data.audio_chunk);
                    break;
                    
                case 'streaming_complete':
                    console.log('Streaming complete:', data.total_chunks_sent, 'chunks');
                    break;
                    
                case 'error':
                    console.error('Server error:', data);
                    updateTranscript('agent', `Error: ${data.message}`);
                    break;
            }
        }
        
        // Voice Button Click Handler
        voiceBtn.onclick = async () => {
            if (!isRecording) {
                await startRecording();
            } else {
                stopRecording();
            }
        };
        
        // Start Recording
        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ 
                    audio: {
                        echoCancellation: true,
                        noiseSuppression: true,
                        sampleRate: 16000
                    } 
                });
                
                // Setup audio context for visualization
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 256;
                source.connect(analyser);
                visualizeAudio();
                
                // Setup media recorder
                mediaRecorder = new MediaRecorder(stream, {
                    mimeType: 'audio/webm'
                });
                
                audioChunks = [];
                
                mediaRecorder.ondataavailable = (event) => {
                    if (event.data.size > 0) {
                        audioChunks.push(event.data);
                        sendAudioChunk(event.data);
                    }
                };
                
                mediaRecorder.onstop = () => {
                    stream.getTracks().forEach(track => track.stop());
                    sendFinalAudioChunk();
                };
                
                mediaRecorder.start(250); // Send chunks every 250ms
                isRecording = true;
                
                voiceBtn.classList.add('recording');
                updateStatus('recording', 'üî¥ Recording... Click to stop');
                buttonLabel.textContent = 'Recording... Click to stop';
                
                console.log('Recording started');
                
            } catch (err) {
                console.error('Failed to start recording:', err);
                alert('Failed to access microphone. Please grant microphone permissions.');
            }
        }
        
        // Stop Recording
        function stopRecording() {
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
                isRecording = false;
                
                voiceBtn.classList.remove('recording');
                updateStatus('connected', 'Processing...');
                buttonLabel.textContent = 'Processing your request...';
                
                if (audioContext) {
                    audioContext.close();
                    audioContext = null;
                }
                
                console.log('Recording stopped');
            }
        }
        
        // Send Audio Chunk via WebSocket
        function sendAudioChunk(blob) {
            const reader = new FileReader();
            reader.onload = () => {
                const base64Audio = btoa(
                    new Uint8Array(reader.result)
                        .reduce((data, byte) => data + String.fromCharCode(byte), '')
                );
                
                const message = {
                    event: 'voice_data',
                    data: {
                        session_id: sessionId,
                        audio_chunk: base64Audio,
                        format: 'webm',
                        sample_rate: 16000,
                        is_final: false
                    }
                };
                
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify(message));
                }
            };
            reader.readAsArrayBuffer(blob);
        }
        
        // Send Final Audio Chunk
        function sendFinalAudioChunk() {
            if (audioChunks.length === 0) return;
            
            const finalBlob = new Blob(audioChunks, { type: 'audio/webm' });
            const reader = new FileReader();
            
            reader.onload = () => {
                const base64Audio = btoa(
                    new Uint8Array(reader.result)
                        .reduce((data, byte) => data + String.fromCharCode(byte), '')
                );
                
                const message = {
                    event: 'voice_data',
                    data: {
                        session_id: sessionId,
                        audio_chunk: base64Audio,
                        format: 'webm',
                        sample_rate: 16000,
                        is_final: true
                    }
                };
                
                if (ws && ws.readyState === WebSocket.OPEN) {
                    ws.send(JSON.stringify(message));
                    console.log('Final audio chunk sent');
                }
            };
            
            reader.readAsArrayBuffer(finalBlob);
        }
        
        // Play Audio Chunk
        function playAudioChunk(base64Audio) {
            audioQueue.push(base64Audio);
            if (!isPlaying) {
                playNextAudio();
            }
        }
        
        async function playNextAudio() {
            if (audioQueue.length === 0) {
                isPlaying = false;
                updateStatus('connected', 'Connected - Ready to talk!');
                buttonLabel.textContent = 'Click to start talking';
                return;
            }
            
            isPlaying = true;
            const base64Audio = audioQueue.shift();
            
            try {
                const audioData = atob(base64Audio);
                const arrayBuffer = new Uint8Array(audioData.length);
                for (let i = 0; i < audioData.length; i++) {
                    arrayBuffer[i] = audioData.charCodeAt(i);
                }
                
                const blob = new Blob([arrayBuffer], { type: 'audio/mpeg' });
                const audioUrl = URL.createObjectURL(blob);
                
                audioPlayer.src = audioUrl;
                audioPlayer.onended = () => {
                    URL.revokeObjectURL(audioUrl);
                    playNextAudio();
                };
                
                await audioPlayer.play();
                
            } catch (err) {
                console.error('Failed to play audio:', err);
                playNextAudio();
            }
        }
        
        // Audio Visualization
        function visualizeAudio() {
            if (!analyser || !isRecording) return;
            
            const dataArray = new Uint8Array(analyser.frequencyBinCount);
            analyser.getByteFrequencyData(dataArray);
            
            const bars = visualizer.querySelectorAll('.audio-bar');
            const step = Math.floor(dataArray.length / bars.length);
            
            bars.forEach((bar, i) => {
                const value = dataArray[i * step];
                const height = Math.max(10, (value / 255) * 60);
                bar.style.height = height + 'px';
            });
            
            requestAnimationFrame(visualizeAudio);
        }
        
        // Update Status
        function updateStatus(state, text) {
            statusDiv.className = `status ${state}`;
            statusDiv.textContent = text;
        }
        
        // Update Transcript
        function updateTranscript(type, text) {
            // Remove any existing partial transcription
            if (type !== 'partial') {
                const partials = transcriptDiv.querySelectorAll('.partial');
                partials.forEach(p => p.remove());
            }
            
            // Remove placeholder if exists
            const placeholder = transcriptDiv.querySelector('[style*="color: #999"]');
            if (placeholder) placeholder.remove();
            
            const item = document.createElement('div');
            item.className = `transcript-item ${type}`;
            
            const label = document.createElement('div');
            label.className = 'label';
            label.textContent = type === 'user' ? 'You:' : 
                              type === 'agent' ? 'Agent:' : 
                              'Listening...';
            
            const textDiv = document.createElement('div');
            textDiv.className = 'text';
            textDiv.textContent = text;
            
            item.appendChild(label);
            item.appendChild(textDiv);
            
            if (type === 'partial') {
                const existing = transcriptDiv.querySelector('.partial');
                if (existing) {
                    existing.replaceWith(item);
                } else {
                    transcriptDiv.appendChild(item);
                }
            } else {
                transcriptDiv.appendChild(item);
            }
            
            transcriptDiv.scrollTop = transcriptDiv.scrollHeight;
        }
        
        // Clear Transcript
        function clearTranscript() {
            transcriptDiv.innerHTML = '<div style="color: #999; text-align: center;">Conversation will appear here...</div>';
        }
        
        // Test Connection
        function testConnection() {
            if (ws && ws.readyState === WebSocket.OPEN) {
                const testMessage = {
                    event: 'voice_command',
                    data: {
                        session_id: sessionId,
                        command: 'tell me the latest tech news',
                        confidence: 0.95
                    }
                };
                ws.send(JSON.stringify(testMessage));
                updateTranscript('user', 'tell me the latest tech news');
                console.log('Test command sent');
            } else {
                alert('Not connected to server');
            }
        }
    </script>
</body>
</html>

